{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ddd44e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23af6ff61cb0444a9c08713d51b7faec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alexa\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd504edfd61412abe4aaaac02fb1808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8db776e710e4018a2bacc465bfad4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d34b00b022b4a1487aeca96a32a257f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45798ebd23a340fd8882b05b1742813f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128f10b64ea74c8591c39e538f1e09d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47499c71d644222a7e07a94ff9e19b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  5%|████▏                                                                              | 1/20 [00:01<00:19,  1.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_joke = What are minorities? Lesser people.\n",
      "nonjoke = No, the math book includes half of the problems.\n",
      "\n",
      "Example 3:\n",
      "\n",
      "Joke: Why did you have to go to college to\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 2/20 [00:01<00:17,  1.06it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_joke = Did you hear that Donald Trump is technically a plant? Because all of his cells have built a wall.\n",
      "nonjoke = Donald Trump is a plant.\n",
      "\n",
      "Example 3:\n",
      "\n",
      "Joke: Do you want to go to a football game and play basketball? You\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▍                                                                      | 3/20 [00:02<00:15,  1.09it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_joke = i had trouble swallowing a viagra last night my neck was stiff for 4 hours\n",
      "nonjoke = I didn't drink it all the time\n",
      "\n",
      "Example 3:\n",
      "\n",
      "Joke: Why was the math book sad? It had too many problems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 4/20 [00:03<00:14,  1.10it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_joke = What is the king of all school supplies? The Ruler\n",
      "nonjoke = The Ruler is a liar, a fool, and a cheat.\n",
      "\n",
      "Example 3:\n",
      "\n",
      "Joke: Why do your friends steal my phone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 8/20 [00:04<00:05,  2.31it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_joke = Why did the producers of 007 films use government debt to fund their newest film? Because interest in the Bond is so low.\n",
      "nonjoke = The government doesn't need to pay people to do what they do.\n",
      "\n",
      "Example 3:\n",
      "\n",
      "Joke: Why did the first movie with\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|█████████████████████████████████████▎                                             | 9/20 [00:05<00:05,  1.93it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_joke = Pocket empty day ! Happy pocket empty day.\n",
      "nonjoke = A day out in the world is a day.\n",
      "\n",
      "Example 3:\n",
      "\n",
      "Joke: The next day is the next day.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████                                         | 10/20 [00:06<00:06,  1.66it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_joke = I want to see that new movie coming out with Scarlett Johannson… …but she probably isn't available.\n",
      "nonjoke = She's not available.\n",
      "\n",
      "Example 3:\n",
      "\n",
      "Joke: I can't believe I'm going to end up in a hospital. You\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▏                                | 12/20 [00:07<00:04,  1.86it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_joke = Why is it so hard to break up with a Japanese Girl? You have to drop the Bomb twice before she gets the Message.\n",
      "nonjoke = It is actually not hard to break up with a Japanese Girl.\n",
      "\n",
      "Example 3:\n",
      "\n",
      "Joke: Why are the girls so stupid?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████████▌                    | 15/20 [00:08<00:02,  2.34it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_joke = My wife wants to eat somewhere shes never eaten before for V-Day I told her she should try the kitchen\n",
      "nonjoke = She is crazy.\n",
      "\n",
      "Example 3:\n",
      "\n",
      "Joke: I get a lot of mail from different countries that say they are not going to\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████████████████▊        | 18/20 [00:08<00:00,  2.67it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_joke = There are two types of people The ones who bang on the wall, And the ones who bang on the wall because I'm banging my girlfriend on the wall\n",
      "nonjoke = I hate people who bang on the wall.\n",
      "\n",
      "Example 3:\n",
      "Joke: Whoops, I think I was a bad math teacher.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████████████████████▉    | 19/20 [00:09<00:00,  2.21it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_joke = Why did the computer squeak? Someone stepped on its mouse.\n",
      "nonjoke = Someone stepped on its mouse.\n",
      "\n",
      "Example 3:\n",
      "\n",
      "Joke: Why did the computer squeak? Someone stepped on its mouse.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:10<00:00,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_joke = i found a place where the recycling rate is 98%. Your moms bed.\n",
      "nonjoke = The recycling rate is 98%. Your moms bed. Example 2:\n",
      "\n",
      "Joke: how long do you have to wait before you can sell the\n",
      "Saved 12 joke-unfunny pairs to joke_unfunny_pairs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"openai-community/gpt2\")\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    return text.replace('\\n', ' ').replace('\\r', ' ').replace('\"', \"'\").strip()\n",
    "\n",
    "def generate_output(prompt):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(inputs, max_length=inputs.shape[1] + 30, temperature=0.7, do_sample=True)\n",
    "    return tokenizer.decode(outputs[0])[len(prompt):].strip()\n",
    "\n",
    "# Load jokes from JSON\n",
    "with open(\"reddit_jokes.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    jokes_data = json.load(f)\n",
    "\n",
    "# Output list\n",
    "joke_pairs = []\n",
    "\n",
    "# Process each joke\n",
    "for joke in tqdm(jokes_data[26:46]):\n",
    "    title = joke.get(\"title\", \"\").strip()\n",
    "    body = joke.get(\"body\", \"\").strip()\n",
    "    full_joke = clean_text(f\"{title} {body}\")\n",
    "    if len(full_joke) > 140:\n",
    "        continue  # Skip jokes that are too long\n",
    "\n",
    "    if not full_joke:\n",
    "        continue  # skip if empty\n",
    "\n",
    "    prompt = (\n",
    "        \"Convert the following joke into a neutral, non-humorous statement. Remove any humor, exaggeration, or playful language. \"\n",
    "        \"The output should be a serious version of the statement.\\n\\n\"\n",
    "        \"Example 1:\\n\"\n",
    "        \"Joke: Why don't skeletons fight each other? They don't have the guts.\\n\"\n",
    "        \"Non-humorous statement: Skeletons lack internal organs, so they cannot fight.\\n\\n\"\n",
    "        \"Example 2:\\n\"\n",
    "        \"Joke: Why was the math book sad? It had too many problems.\\n\"\n",
    "        \"Non-humorous statement: The math book contains a lot of problems.\\n\\n\"\n",
    "        \"Now, please convert the following joke into a non-humorous statement:\\n\"\n",
    "        f\"Joke: {full_joke}\\nNon-humorous statement:\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        unfunny = generate_output(prompt)\n",
    "    except Exception as e:\n",
    "        print(f\"Error with joke: {full_joke[:60]}... | {str(e)}\")\n",
    "        continue\n",
    "\n",
    "    joke_pairs.append({\n",
    "        \"joke\": full_joke,\n",
    "        \"unfunny\": unfunny\n",
    "    })\n",
    "    print(f\"full_joke = {full_joke}\")\n",
    "    print(f\"nonjoke = {unfunny}\")\n",
    "\n",
    "\n",
    "# Save to new JSON\n",
    "with open(\"joke_unfunny_pairs.json\", \"w\", encoding=\"utf-8\") as f_out:\n",
    "    json.dump(joke_pairs, f_out, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved {len(joke_pairs)} joke-unfunny pairs to joke_unfunny_pairs.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218a632d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
